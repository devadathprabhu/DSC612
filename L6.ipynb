{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devadathprabhu/DSC612/blob/main/L6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kirHMXJ8S7x",
        "outputId": "e90a908b-ac38-47dd-b7a9-ceeb831b4141"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57P3N1bAG3KY",
        "outputId": "a0f09b28-9615-43f4-a43e-8e884fbdcc9d"
      },
      "source": [
        "import os, cv2, itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install np_utils\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "!pip install sklearn\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.5.12.1.tar.gz (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.7/dist-packages (from np_utils) (0.16.0)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.5.12.1-py3-none-any.whl size=57131 sha256=e11b80bb2fe59f897253573dbbd48cbbba489d605680ae994cee6334f422ecfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/4e/ef/095c24693723c329f4cdc1079861cdbb2487d4b41b2496a4e7\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.5.12.1\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH8HVB_AG5ia"
      },
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/DL/train/'\n",
        "TEST_DIR = '/content/drive/MyDrive/DL/test/'\n",
        "\n",
        "ROWS = 32\n",
        "COLS = 32\n",
        "CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mir4b_QgHJPy"
      },
      "source": [
        "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBc0Hc2oHOCp"
      },
      "source": [
        "def read_image(file_path):\n",
        "  #print(file_path)\n",
        "  img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "  #print(img)\n",
        "  return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYJoE-8DHPHC"
      },
      "source": [
        "def prep_data(images):\n",
        "  m = len(images)\n",
        "  n_x = ROWS*COLS*CHANNELS\n",
        "  \n",
        "  X = np.ndarray((m,ROWS,COLS,CHANNELS), dtype=np.uint8)\n",
        "  y = np.zeros((m,1))\n",
        "  print(\"X.shape is {}\".format(X.shape))\n",
        "  \n",
        "  for i,image_file in enumerate(images) :\n",
        "    image = read_image(image_file)\n",
        "    X[i,:] = np.squeeze(image.reshape((ROWS, COLS, CHANNELS)))\n",
        "    if 'dog' in image_file.lower() :\n",
        "      y[i,0] = 1\n",
        "    elif 'cat' in image_file.lower() :\n",
        "      y[i,0] = 0\n",
        "    else : # for test data\n",
        "      y[i,0] = image_file.split('/')[-1].split('.')[0]\n",
        "      \n",
        "    if i%5000 == 0 :\n",
        "      print(\"Proceed {} of {}\".format(i, m))\n",
        "    \n",
        "  return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtKgShCoHT1o",
        "outputId": "0ed3341d-d1da-470e-a1c2-9808058dbc5c"
      },
      "source": [
        "x_train, y_train = prep_data(train_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape is (615, 32, 32, 3)\n",
            "Proceed 0 of 615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBTIwO8yIWqL",
        "outputId": "e7a09c42-9d6c-4ee6-db5f-d188929d092f"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=.4)\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.2)\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((295, 32, 32, 3), (295, 2))\n",
            "((74, 32, 32, 3), (74, 2))\n",
            "((246, 32, 32, 3), (246, 2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a22FdEysLFCU"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_generator = ImageDataGenerator(rotation_range=2, \n",
        "                                     horizontal_flip=True,zoom_range=.1 )\n",
        "val_generator = ImageDataGenerator(rotation_range=2, \n",
        "                                   horizontal_flip=True,zoom_range=.1)\n",
        "test_generator = ImageDataGenerator(rotation_range=2, \n",
        "                                    horizontal_flip= True,zoom_range=.1)\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk1QxOktLc67",
        "outputId": "ff939ebe-ece3-48b7-aca4-beb398224ab7"
      },
      "source": [
        "#Importing library\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96,input_shape=(32,32,3),kernel_size=(11,11),\n",
        "                   strides=(4,4),padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(2))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 96)          34944     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 8, 8, 96)         384       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 8, 8, 96)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 96)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 256)         614656    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2, 2, 384)        1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 2, 2, 384)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 2, 2, 384)        1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 2, 2, 384)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 1, 1, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              1052672   \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 4096)             16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 1000)             4000      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 1000)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 2002      \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,722,466\n",
            "Trainable params: 25,701,326\n",
            "Non-trainable params: 21,140\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yp6vA_L6_c"
      },
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy,\n",
        "                optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygSP63IPQC5e"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5)\n",
        "#Defining the parameters\n",
        "batch_size=15\n",
        "epochs=20\n",
        "learn_rate=.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFkuh-6pL-7g",
        "outputId": "feb2e2c4-34d0-4845-d012-1227309616c6"
      },
      "source": [
        "AlexNet.fit_generator(\n",
        "    train_generator.flow(x_train, y_train, batch_size=batch_size),\n",
        "     epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size,\n",
        "      validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size),\n",
        "       validation_steps = 250, callbacks = [lrr], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.6143WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "19/19 [==============================] - 8s 446ms/step - loss: 0.6642 - accuracy: 0.6143 - val_loss: 28.5806 - val_accuracy: 0.3919 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.5893WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 421ms/step - loss: 0.6702 - accuracy: 0.5893 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.6357WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 429ms/step - loss: 0.6532 - accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.6929WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 420ms/step - loss: 0.6162 - accuracy: 0.6929 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7053WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 425ms/step - loss: 0.5875 - accuracy: 0.7053 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5967 - accuracy: 0.6821WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 425ms/step - loss: 0.5967 - accuracy: 0.6821 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.7214WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 427ms/step - loss: 0.5766 - accuracy: 0.7214 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.7536WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 423ms/step - loss: 0.5366 - accuracy: 0.7536 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.7107WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 429ms/step - loss: 0.5721 - accuracy: 0.7107 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.6964WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 424ms/step - loss: 0.5759 - accuracy: 0.6964 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.7464WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 421ms/step - loss: 0.5146 - accuracy: 0.7464 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.7893WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 423ms/step - loss: 0.4949 - accuracy: 0.7893 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.7643WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 424ms/step - loss: 0.5122 - accuracy: 0.7643 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.7750WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 429ms/step - loss: 0.4817 - accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.7714WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 430ms/step - loss: 0.4962 - accuracy: 0.7714 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.7893WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 429ms/step - loss: 0.4575 - accuracy: 0.7893 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8179WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 424ms/step - loss: 0.4179 - accuracy: 0.8179 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8464WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 421ms/step - loss: 0.3903 - accuracy: 0.8464 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8286WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 422ms/step - loss: 0.3685 - accuracy: 0.8286 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.8500WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "19/19 [==============================] - 8s 421ms/step - loss: 0.3484 - accuracy: 0.8500 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0574e2aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Ipz_XKSdVCwD",
        "outputId": "47169542-436d-41ac-86b2-2c4e2ef7fcd8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Plotting the training and validation loss\n",
        "\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assigning the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(AlexNet.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(AlexNet.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Plotting the training accuracy and validation accuracy\n",
        "ax[1].plot(AlexNet.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(AlexNet.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0574df3810>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}